Borrowing the fine-tuning and testing API provided at https://github.com/GlassyWu/AECR-Net, we have first carried out a simple inference pass to augment our dataset for YOLO, and then performed finetuning on the intial hazy images and their ground truths. The initial inference outputs are located in `inference/` while the inference outputs after fine-tuning are located at `fine_tuned_output/`.
